{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modeling Local Demographics based on Local Venues in Toronto, Canada", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "*By Andrew Dahlstrom*\n\n*10/04/2019*", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Introduction\n\nThis Notebook is my submission for the final project in the IBM Applied Data Science Capstone Course. This assignment requires that I design an imagined scenario which will allow me to demonstrate the techniques and methodologies I have learned in the IBM Applied Data Science Specialization program as well as utilize the FourSquare API and the scikit-learn library for learning algorithms in Python. The scenario I devised for this project is that I have been contracted by International Health Organization to conduct an exploratory case study with the goal to improve methodologies for building demographic maps. To accomplish this goal, I have chosen to experiment with modeling and predicting local demographics based on local venue data for neighborhoods in the city of Toronto, Canada. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Background\n\nPopulation demographic maps are useful tools for many humanitarian efforts including to manage disease outbreaks, water scarcity, disaster relief efforts, electrical grid expansion, expansion of health or education services etc. Demographic data is not always readily available in some areas so any contribution to methodology that can improve the accuracy of population maps could be useful to humanitarian efforts. In the past studies have been presented showing the use of age demographic data to predict the success of a venue opening in that neighborhood; however, it seems predicting age demographics from neighborhood venues has not been fully explored. not been The goal of this project is to explore how accurately local venue data can predict the demographic data for a neighborhood (categorized by postal code) by using relevant machine learning techniques to build a prediction model. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Data\n\nThis city of Toronto was selected because of the detailed and recent demographic data available publicly and the large collection of venue data available for each neighborhood. The data for this project has been collected from the following sources:\n\n* Toronto postal code data can be found on [Wikipedia](https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M).\n* The demographic data for Toronto has been collected from the [2016 Census](https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/pd-pl/Table.cfm?Lang=Eng&T=1201&S=22&O=A).\n* The local venue data will be retrieved from the [FourSquare API](https://developer.foursquare.com/).\n* Latitude and longitude geospatial data for postal codes provided by IBM course website", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Construct Dataframes\nThe first step is to create a dataframe of postal codes for the city of Toronto using a web scraper in order to organize the venue and demographic data into smaller communities.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from bs4 import BeautifulSoup\nimport requests\nimport numpy as np\nimport pandas as pd"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M3A</td>\n      <td>North York</td>\n      <td>Parkwoods</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M4A</td>\n      <td>North York</td>\n      <td>Victoria Village</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Harbourfront</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Regent Park</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M6A</td>\n      <td>North York</td>\n      <td>Lawrence Heights</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code           Borough      Neighborhood\n0         M3A        North York         Parkwoods\n1         M4A        North York  Victoria Village\n2         M5A  Downtown Toronto      Harbourfront\n3         M5A  Downtown Toronto       Regent Park\n4         M6A        North York  Lawrence Heights"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Scrape text from wikitable online and load into a Pandas data frame\n\nsource = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\nsoup = BeautifulSoup(source, 'lxml')\n#print(soup.prettify())\n\nfor table in soup.find_all('table', class_= 'wikitable'):\n    neightable = []\n    \n    for row in table.find_all('tr'):\n        neighrow = []\n        \n        for data in row.find_all('td'):\n            neighrow.append(data.text.rstrip('\\n'))\n        \n        neightable.append(neighrow)\n\n#Clean data remove unassigned boroughs\nneighdf = pd.DataFrame(neightable, columns = ['Postal Code', 'Borough', 'Neighborhood'])\nneighdf.drop(index=0, inplace=True)\ntodrop = neighdf[neighdf['Borough'] == \"Not assigned\"].index\nneighdf.drop(todrop, inplace=True)\nneighdf.reset_index(drop=True).head(5)"
        }, 
        {
            "source": "In order to clean the Toronto postal code data we need to merge neighborhoods that share the same postal code and give unnamed neighbourhoods the name of their borough.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Rouge, Malvern</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>Scarborough</td>\n      <td>Highland Creek, Rouge Hill, Port Union</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>Scarborough</td>\n      <td>Guildwood, Morningside, West Hill</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>Scarborough</td>\n      <td>Woburn</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>Scarborough</td>\n      <td>Cedarbrae</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code      Borough                            Neighborhood\n0         M1B  Scarborough                          Rouge, Malvern\n1         M1C  Scarborough  Highland Creek, Rouge Hill, Port Union\n2         M1E  Scarborough       Guildwood, Morningside, West Hill\n3         M1G  Scarborough                                  Woburn\n4         M1H  Scarborough                               Cedarbrae"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Replace unassigned neighborhoods or neighborhoods with incorrect names with their borough name \n\nfor index, row in neighdf.iterrows(): \n    s = neighdf.at[index, 'Neighborhood']\n    if  s == \"Not assigned\" or len(s.split()) > 4 :\n        neighdf.at[index, 'Neighborhood'] = neighdf.at[index, 'Borough']\n\n# Merge neighborhoods with same postalcode\n\nneighdf = neighdf.groupby(['Postal Code','Borough'])['Neighborhood'].apply(', '.join).reset_index()\nneighdf.head(5)       "
        }, 
        {
            "source": "Next we need to get the csv file from the link provided in the course website to get the latitude and longitude coordinates for each postal code.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>43.806686</td>\n      <td>-79.194353</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>43.784535</td>\n      <td>-79.160497</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>43.763573</td>\n      <td>-79.188711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>43.770992</td>\n      <td>-79.216917</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>43.773136</td>\n      <td>-79.239476</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code   Latitude  Longitude\n0         M1B  43.806686 -79.194353\n1         M1C  43.784535 -79.160497\n2         M1E  43.763573 -79.188711\n3         M1G  43.770992 -79.216917\n4         M1H  43.773136 -79.239476"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import io\ngeourl=\"http://cocl.us/Geospatial_data\"\ns = requests.get(geourl).content\ngeodata = pd.read_csv(io.StringIO(s.decode('utf-8')))\ngeodata.head(5)"
        }, 
        {
            "source": "Add latitude and longitude data to neighborhood dataframe.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(103, 5)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "for index, row in neighdf.iterrows():   \n    for i, r in geodata.iterrows():\n        if neighdf.at[index, 'Postal Code'] == geodata.at[i, 'Postal Code']:\n            neighdf.at[index, 'Latitude'] = geodata.at[i, 'Latitude']\n            neighdf.at[index, 'Longitude'] = geodata.at[i, 'Longitude']\n\nneighdf.shape"
        }, 
        {
            "source": "Next we need the FourSquare API to get the venue data for each postal code.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "### Create dataframe containing venue data for each postal code ###\n\n# Define function to get venue data for each postal code.\n# Takes as an argument location name, latitude and logitude coordinates\n# returns a dataframe containing venue data for the nearest \n# LIMIT number of venues within the radius\n\n# Max number of venues within radius\nLIMIT = 100\n\ndef getNearbyVenues(names, latitudes, longitudes, radius=7000):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}&time={}&day={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius,\n            LIMIT,\n            any,\n            any)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n        nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n        nearby_venues.columns = ['Postal Code', \n                  'Postal Code Latitude', \n                  'Postal Code Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 8, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(10300, 7)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Create the dataframe using the getNearbyVenues function\n\nvenues = getNearbyVenues(names=neighdf['Postal Code'],\n                                 latitudes=neighdf['Latitude'],\n                                 longitudes=neighdf['Longitude'],\n                                )\n\nvenues.shape"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "There are 226 unique venue categories and the following venue counts for each postal code.\n"
                }, 
                {
                    "execution_count": 9, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code Latitude</th>\n      <th>Postal Code Longitude</th>\n      <th>Venue</th>\n      <th>Venue Latitude</th>\n      <th>Venue Longitude</th>\n      <th>Venue Category</th>\n    </tr>\n    <tr>\n      <th>Postal Code</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>M1B</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1C</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1E</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1G</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1H</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "             Postal Code Latitude  Postal Code Longitude  Venue  \\\nPostal Code                                                       \nM1B                           100                    100    100   \nM1C                           100                    100    100   \nM1E                           100                    100    100   \nM1G                           100                    100    100   \nM1H                           100                    100    100   \n\n             Venue Latitude  Venue Longitude  Venue Category  \nPostal Code                                                   \nM1B                     100              100             100  \nM1C                     100              100             100  \nM1E                     100              100             100  \nM1G                     100              100             100  \nM1H                     100              100             100  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "print('There are {} unique venue categories and the following venue counts for each postal code.'.format(len(venues['Venue Category'].unique())))\nvenues.groupby('Postal Code').count().head(5)"
        }, 
        {
            "source": "Now that we have the venue data, the next step is to build the dataframe of neighborhood venue profiles for each postal code. I will use a method called one hot encoding to build a binary classification table which can then be used to build a frequency table for the occurences of a venue in each category for each postal code. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Afghan Restaurant</th>\n      <th>Airport</th>\n      <th>Airport Lounge</th>\n      <th>American Restaurant</th>\n      <th>Aquarium</th>\n      <th>Art Gallery</th>\n      <th>Arts &amp; Crafts Store</th>\n      <th>Asian Restaurant</th>\n      <th>Athletics &amp; Sports</th>\n      <th>...</th>\n      <th>Vegetarian / Vegan Restaurant</th>\n      <th>Vietnamese Restaurant</th>\n      <th>Warehouse Store</th>\n      <th>Whisky Bar</th>\n      <th>Wine Bar</th>\n      <th>Wings Joint</th>\n      <th>Women's Store</th>\n      <th>Yoga Studio</th>\n      <th>Zoo</th>\n      <th>Zoo Exhibit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 227 columns</p>\n</div>", 
                        "text/plain": "  Postal Code  Afghan Restaurant  Airport  Airport Lounge  \\\n0         M1B                0.0      0.0             0.0   \n1         M1C                0.0      0.0             0.0   \n2         M1E                0.0      0.0             0.0   \n3         M1G                0.0      0.0             0.0   \n4         M1H                0.0      0.0             0.0   \n\n   American Restaurant  Aquarium  Art Gallery  Arts & Crafts Store  \\\n0                  0.0       0.0          0.0                 0.00   \n1                  0.0       0.0          0.0                 0.00   \n2                  0.0       0.0          0.0                 0.00   \n3                  0.0       0.0          0.0                 0.01   \n4                  0.0       0.0          0.0                 0.01   \n\n   Asian Restaurant  Athletics & Sports  ...  Vegetarian / Vegan Restaurant  \\\n0              0.01                0.01  ...                           0.00   \n1              0.00                0.01  ...                           0.00   \n2              0.00                0.01  ...                           0.00   \n3              0.02                0.01  ...                           0.00   \n4              0.02                0.01  ...                           0.01   \n\n   Vietnamese Restaurant  Warehouse Store  Whisky Bar  Wine Bar  Wings Joint  \\\n0                   0.00             0.01         0.0       0.0         0.01   \n1                   0.00             0.00         0.0       0.0         0.01   \n2                   0.00             0.00         0.0       0.0         0.00   \n3                   0.01             0.01         0.0       0.0         0.00   \n4                   0.01             0.01         0.0       0.0         0.00   \n\n   Women's Store  Yoga Studio   Zoo  Zoo Exhibit  \n0            0.0          0.0  0.02         0.11  \n1            0.0          0.0  0.02         0.11  \n2            0.0          0.0  0.02         0.10  \n3            0.0          0.0  0.02         0.05  \n4            0.0          0.0  0.00         0.01  \n\n[5 rows x 227 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# One hot encoding\ntoronto_onehot = pd.get_dummies(venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# Add back in postal code column and move it to front\ntoronto_onehot['Postal Code'] = venues['Postal Code']\nfixed_columns = list(toronto_onehot)\nfixed_columns.insert(1, fixed_columns.pop(fixed_columns.index('Postal Code')))\ntoronto_onehot = toronto_onehot.loc[:, fixed_columns]\n\n# Build frequency table by postal code and by taking the mean of the frequency of occurrence for each category\ntoronto_venues = toronto_onehot.groupby('Postal Code').mean().reset_index()\ntoronto_venues.head(5)"
        }, 
        {
            "source": "Now that the neighborhood venue profile dataframe is complete, the next step is to build the neighborhood demographics dataframe using data from the 2016 Canada Census.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 11, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Index</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>Total - Age</td>\n      <td>66110.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1B</td>\n      <td>0 to 14 years</td>\n      <td>11535.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1B</td>\n      <td>0 to 4 years</td>\n      <td>3540.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1B</td>\n      <td>Under 1 year</td>\n      <td>675.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1B</td>\n      <td>1</td>\n      <td>705.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code          Index  Population\n0         M1B    Total - Age     66110.0\n1         M1B  0 to 14 years     11535.0\n2         M1B   0 to 4 years      3540.0\n3         M1B   Under 1 year       675.0\n4         M1B              1       705.0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from zipfile import ZipFile\n\n# Get demographic data from Canada Census website, load into dataframe\nurl = \"https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/dt-td/CompDataDownload.cfm?LANG=E&PID=109790&OFT=CSV\"\nr = requests.get(url)\nz = ZipFile(io.BytesIO(r.content))\nz.extractall()\n\ndemo = pd.read_csv(z.open('98-400-X2016008_English_CSV_data.csv'), \n                     usecols = ['L9Z', 'Average age', '50.0'],\n                     sep = ',', skiprows = 112395, nrows = 12192)\ndemo.rename(columns = {\"L9Z\": \"Postal Code\", \"Average age\": \"Index\", \n                       \"50.0\" : \"Population\"}, inplace = True)\ndemo.head()"
        }, 
        {
            "source": "Next let's organize the table so that the index is postal codes and the columns are population per age groups in increments of 5 years.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Index</th>\n      <th>Postal Code</th>\n      <th>0 to 4 years</th>\n      <th>5 to 9 years</th>\n      <th>10 to 14 years</th>\n      <th>15 to 19 years</th>\n      <th>20 to 24 years</th>\n      <th>25 to 29 years</th>\n      <th>30 to 34 years</th>\n      <th>35 to 39 years</th>\n      <th>40 to 44 years</th>\n      <th>...</th>\n      <th>55 to 59 years</th>\n      <th>60 to 64 years</th>\n      <th>65 to 69 years</th>\n      <th>70 to 74 years</th>\n      <th>75 to 79 years</th>\n      <th>80 to 84 years</th>\n      <th>85 to 89 years</th>\n      <th>90 to 94 years</th>\n      <th>95 to 99 years</th>\n      <th>100 years and over</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>3540.0</td>\n      <td>3920.0</td>\n      <td>4080.0</td>\n      <td>4680.0</td>\n      <td>5090.0</td>\n      <td>4835.0</td>\n      <td>4415.0</td>\n      <td>3950.0</td>\n      <td>4150.0</td>\n      <td>...</td>\n      <td>4570.0</td>\n      <td>4070.0</td>\n      <td>3615.0</td>\n      <td>2470.0</td>\n      <td>1610.0</td>\n      <td>925.0</td>\n      <td>530.0</td>\n      <td>220.0</td>\n      <td>65.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>1575.0</td>\n      <td>1760.0</td>\n      <td>1905.0</td>\n      <td>2380.0</td>\n      <td>2695.0</td>\n      <td>2130.0</td>\n      <td>1870.0</td>\n      <td>1955.0</td>\n      <td>1965.0</td>\n      <td>...</td>\n      <td>2970.0</td>\n      <td>2670.0</td>\n      <td>2340.0</td>\n      <td>1695.0</td>\n      <td>1090.0</td>\n      <td>665.0</td>\n      <td>385.0</td>\n      <td>185.0</td>\n      <td>40.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>2405.0</td>\n      <td>2585.0</td>\n      <td>2585.0</td>\n      <td>3100.0</td>\n      <td>3450.0</td>\n      <td>2975.0</td>\n      <td>2665.0</td>\n      <td>2550.0</td>\n      <td>2720.0</td>\n      <td>...</td>\n      <td>3610.0</td>\n      <td>3050.0</td>\n      <td>2370.0</td>\n      <td>1840.0</td>\n      <td>1545.0</td>\n      <td>1195.0</td>\n      <td>840.0</td>\n      <td>405.0</td>\n      <td>105.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>1720.0</td>\n      <td>1925.0</td>\n      <td>1950.0</td>\n      <td>2140.0</td>\n      <td>2350.0</td>\n      <td>2125.0</td>\n      <td>1835.0</td>\n      <td>1810.0</td>\n      <td>1775.0</td>\n      <td>...</td>\n      <td>1970.0</td>\n      <td>1530.0</td>\n      <td>1320.0</td>\n      <td>1015.0</td>\n      <td>925.0</td>\n      <td>685.0</td>\n      <td>370.0</td>\n      <td>140.0</td>\n      <td>20.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>1330.0</td>\n      <td>1365.0</td>\n      <td>1175.0</td>\n      <td>1320.0</td>\n      <td>1970.0</td>\n      <td>2000.0</td>\n      <td>1910.0</td>\n      <td>1705.0</td>\n      <td>1540.0</td>\n      <td>...</td>\n      <td>1605.0</td>\n      <td>1340.0</td>\n      <td>1010.0</td>\n      <td>820.0</td>\n      <td>670.0</td>\n      <td>655.0</td>\n      <td>385.0</td>\n      <td>185.0</td>\n      <td>35.0</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 22 columns</p>\n</div>", 
                        "text/plain": "Index Postal Code  0 to 4 years  5 to 9 years  10 to 14 years  15 to 19 years  \\\n0             M1B        3540.0        3920.0          4080.0          4680.0   \n1             M1C        1575.0        1760.0          1905.0          2380.0   \n2             M1E        2405.0        2585.0          2585.0          3100.0   \n3             M1G        1720.0        1925.0          1950.0          2140.0   \n4             M1H        1330.0        1365.0          1175.0          1320.0   \n\nIndex  20 to 24 years  25 to 29 years  30 to 34 years  35 to 39 years  \\\n0              5090.0          4835.0          4415.0          3950.0   \n1              2695.0          2130.0          1870.0          1955.0   \n2              3450.0          2975.0          2665.0          2550.0   \n3              2350.0          2125.0          1835.0          1810.0   \n4              1970.0          2000.0          1910.0          1705.0   \n\nIndex  40 to 44 years  ...  55 to 59 years  60 to 64 years  65 to 69 years  \\\n0              4150.0  ...          4570.0          4070.0          3615.0   \n1              1965.0  ...          2970.0          2670.0          2340.0   \n2              2720.0  ...          3610.0          3050.0          2370.0   \n3              1775.0  ...          1970.0          1530.0          1320.0   \n4              1540.0  ...          1605.0          1340.0          1010.0   \n\nIndex  70 to 74 years  75 to 79 years  80 to 84 years  85 to 89 years  \\\n0              2470.0          1610.0           925.0           530.0   \n1              1695.0          1090.0           665.0           385.0   \n2              1840.0          1545.0          1195.0           840.0   \n3              1015.0           925.0           685.0           370.0   \n4               820.0           670.0           655.0           385.0   \n\nIndex  90 to 94 years  95 to 99 years  100 years and over  \n0               220.0            65.0                10.0  \n1               185.0            40.0                 5.0  \n2               405.0           105.0                15.0  \n3               140.0            20.0                 5.0  \n4               185.0            35.0                 5.0  \n\n[5 rows x 22 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "toronto_demo = demo.pivot(index = 'Postal Code', columns = 'Index', values = 'Population')\nkeep_columns = ['0 to 4 years', '5 to 9 years', '10 to 14 years', '15 to 19 years', \n                '20 to 24 years', '25 to 29 years', '30 to 34 years', '35 to 39 years',\n                '40 to 44 years', '45 to 49 years', '50 to 54 years', '55 to 59 years',\n                '60 to 64 years', '65 to 69 years', '70 to 74 years', '75 to 79 years',\n                '80 to 84 years', '85 to 89 years', '90 to 94 years', '95 to 99 years',\n                '100 years and over']\ntoronto_demo = toronto_demo[keep_columns].reset_index()\ntoronto_demo.head()"
        }, 
        {
            "source": "#### Notes about the data: \n\n* The demographic data comes from a 2016 census but the venue data is current meaning that the demographic data is lagging behind the venue data by a couple of years so this will affect the accuracy of the model.\n* For financial reasons I must limit the number of venues I am able to collect data on for each neighborhood. I will therefore find the distribution of the venues for each category within each neighborhood in order to create a venue profile for each neighborhood.  \n* I will be exploring how well venue data predicts the age distribution of the population in each neighborhood separated into 5 year increments.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Methodology\nNow it's time for the exciting part! First I will test different machine learning regression algorithms from the sklearn package to fit the venue data then analyze which model is best at predicting neighborhood age demographics. Second, I will take a different approach to understanding the relationship between dataframes by utilizing clustering techniques to look for trends between venues and age demographics. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Preprocess Data\nFirst we can normalize our data by finding the mean for each category and then subtracting that from the mean of each postal code. This will make it easier to notice differences between the neighborhoods. We can also use sklearn built in preprocessing to normalize our labels and features with the StandardScaler.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 13, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(96, 226)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from sklearn.preprocessing import StandardScaler\nfeatures_scaler = StandardScaler()\n\nfeatures = toronto_venues\n\n# Drop the rows in the features set that we do not have population data for\nrowsDrop = list(set(toronto_venues['Postal Code']).symmetric_difference(set(toronto_demo['Postal Code'])))\nfeatures.drop(features.loc[features['Postal Code'].isin(rowsDrop)].index, inplace=True)\n\n# Drop Postal Code column to have all numeric\nfeatures.drop(['Postal Code'], axis = 1, inplace = True)\nfeatures.shape"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 14, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Index</th>\n      <th>0 to 4 years</th>\n      <th>5 to 9 years</th>\n      <th>10 to 14 years</th>\n      <th>15 to 19 years</th>\n      <th>20 to 24 years</th>\n      <th>25 to 29 years</th>\n      <th>30 to 34 years</th>\n      <th>35 to 39 years</th>\n      <th>40 to 44 years</th>\n      <th>45 to 49 years</th>\n      <th>...</th>\n      <th>55 to 59 years</th>\n      <th>60 to 64 years</th>\n      <th>65 to 69 years</th>\n      <th>70 to 74 years</th>\n      <th>75 to 79 years</th>\n      <th>80 to 84 years</th>\n      <th>85 to 89 years</th>\n      <th>90 to 94 years</th>\n      <th>95 to 99 years</th>\n      <th>100 years and over</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.053547</td>\n      <td>0.059295</td>\n      <td>0.061715</td>\n      <td>0.070791</td>\n      <td>0.076993</td>\n      <td>0.073136</td>\n      <td>0.066783</td>\n      <td>0.059749</td>\n      <td>0.062774</td>\n      <td>0.066707</td>\n      <td>...</td>\n      <td>0.069127</td>\n      <td>0.061564</td>\n      <td>0.054682</td>\n      <td>0.037362</td>\n      <td>0.024353</td>\n      <td>0.013992</td>\n      <td>0.008017</td>\n      <td>0.003328</td>\n      <td>0.000983</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.044204</td>\n      <td>0.049397</td>\n      <td>0.053466</td>\n      <td>0.066798</td>\n      <td>0.075639</td>\n      <td>0.059781</td>\n      <td>0.052484</td>\n      <td>0.054869</td>\n      <td>0.055150</td>\n      <td>0.067078</td>\n      <td>...</td>\n      <td>0.083357</td>\n      <td>0.074937</td>\n      <td>0.065675</td>\n      <td>0.047572</td>\n      <td>0.030592</td>\n      <td>0.018664</td>\n      <td>0.010806</td>\n      <td>0.005192</td>\n      <td>0.001123</td>\n      <td>0.000140</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.051219</td>\n      <td>0.055053</td>\n      <td>0.055053</td>\n      <td>0.066021</td>\n      <td>0.073475</td>\n      <td>0.063359</td>\n      <td>0.056756</td>\n      <td>0.054307</td>\n      <td>0.057928</td>\n      <td>0.069002</td>\n      <td>...</td>\n      <td>0.076882</td>\n      <td>0.064956</td>\n      <td>0.050474</td>\n      <td>0.039186</td>\n      <td>0.032904</td>\n      <td>0.025450</td>\n      <td>0.017889</td>\n      <td>0.008625</td>\n      <td>0.002236</td>\n      <td>0.000319</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.057932</td>\n      <td>0.064837</td>\n      <td>0.065679</td>\n      <td>0.072078</td>\n      <td>0.079151</td>\n      <td>0.071573</td>\n      <td>0.061805</td>\n      <td>0.060963</td>\n      <td>0.059784</td>\n      <td>0.065173</td>\n      <td>...</td>\n      <td>0.066352</td>\n      <td>0.051533</td>\n      <td>0.044459</td>\n      <td>0.034187</td>\n      <td>0.031155</td>\n      <td>0.023072</td>\n      <td>0.012462</td>\n      <td>0.004715</td>\n      <td>0.000674</td>\n      <td>0.000168</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.054508</td>\n      <td>0.055943</td>\n      <td>0.048156</td>\n      <td>0.054098</td>\n      <td>0.080738</td>\n      <td>0.081967</td>\n      <td>0.078279</td>\n      <td>0.069877</td>\n      <td>0.063115</td>\n      <td>0.068033</td>\n      <td>...</td>\n      <td>0.065779</td>\n      <td>0.054918</td>\n      <td>0.041393</td>\n      <td>0.033607</td>\n      <td>0.027459</td>\n      <td>0.026844</td>\n      <td>0.015779</td>\n      <td>0.007582</td>\n      <td>0.001434</td>\n      <td>0.000205</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>", 
                        "text/plain": "Index  0 to 4 years  5 to 9 years  10 to 14 years  15 to 19 years  \\\n0          0.053547      0.059295        0.061715        0.070791   \n1          0.044204      0.049397        0.053466        0.066798   \n2          0.051219      0.055053        0.055053        0.066021   \n3          0.057932      0.064837        0.065679        0.072078   \n4          0.054508      0.055943        0.048156        0.054098   \n\nIndex  20 to 24 years  25 to 29 years  30 to 34 years  35 to 39 years  \\\n0            0.076993        0.073136        0.066783        0.059749   \n1            0.075639        0.059781        0.052484        0.054869   \n2            0.073475        0.063359        0.056756        0.054307   \n3            0.079151        0.071573        0.061805        0.060963   \n4            0.080738        0.081967        0.078279        0.069877   \n\nIndex  40 to 44 years  45 to 49 years  ...  55 to 59 years  60 to 64 years  \\\n0            0.062774        0.066707  ...        0.069127        0.061564   \n1            0.055150        0.067078  ...        0.083357        0.074937   \n2            0.057928        0.069002  ...        0.076882        0.064956   \n3            0.059784        0.065173  ...        0.066352        0.051533   \n4            0.063115        0.068033  ...        0.065779        0.054918   \n\nIndex  65 to 69 years  70 to 74 years  75 to 79 years  80 to 84 years  \\\n0            0.054682        0.037362        0.024353        0.013992   \n1            0.065675        0.047572        0.030592        0.018664   \n2            0.050474        0.039186        0.032904        0.025450   \n3            0.044459        0.034187        0.031155        0.023072   \n4            0.041393        0.033607        0.027459        0.026844   \n\nIndex  85 to 89 years  90 to 94 years  95 to 99 years  100 years and over  \n0            0.008017        0.003328        0.000983            0.000151  \n1            0.010806        0.005192        0.001123            0.000140  \n2            0.017889        0.008625        0.002236            0.000319  \n3            0.012462        0.004715        0.000674            0.000168  \n4            0.015779        0.007582        0.001434            0.000205  \n\n[5 rows x 21 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "labels_scaler = StandardScaler()\n\nlabels = toronto_demo\nlabels.drop(['Postal Code'], axis = 1, inplace = True)\nlabels = toronto_demo.apply(lambda x: x / x.sum(), axis = 1)\nlabels.head()"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "norm_features = features_scaler.fit_transform(features)\nnorm_labels = labels_scaler.fit_transform(labels)"
        }, 
        {
            "source": "#### Split the Data into Training and Testing Sets:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train set: (76, 226) (76, 21)\nTest set: (20, 226) (20, 21)\n"
                }
            ], 
            "source": "from sklearn.model_selection import train_test_split\n\n#Split the training data into a training and testing set\n#Note the switch between features and labels\nX_train, X_test, y_train, y_test = train_test_split(norm_features, norm_labels, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        }, 
        {
            "source": "#### Find the best Regression Model :", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "from sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn import neighbors \n\nbest_rscore = 0\nbest_model = 0\nbest_ev = 0\n\nregressors = [\n    #Linear regressors \n    #linear_model.LinearRegression(),\n    #linear_model.SGDRegressor(),\n    \n    linear_model.BayesianRidge(),\n    #linear_model.LassoLars(),\n    #linear_model.PassiveAggressiveRegressor(),\n    #linear_model.TheilSenRegressor(),\n    \n    #KNN regressors\n    neighbors.KNeighborsRegressor(),\n    #neighbors.RadiusNeighborsRegressor()\n    ]\n\nfor r in regressors:\n    mr =  MultiOutputRegressor(r)\n    mr.fit(X_train, y_train)\n    yhat = mr.predict(X_test)\n    this_rscore = r2_score(y_test, yhat, multioutput='uniform_average')\n    this_ev = explained_variance_score(y_test, yhat, multioutput = 'uniform_average')\n    \n    if (best_ev < this_ev) :\n        best_model = mr\n        best_rscore = this_rscore\n        best_ev = this_ev"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfor d in range(1, 5):\n\n    regressors = [\n        DecisionTreeRegressor(max_depth = d),\n        ExtraTreesRegressor(max_depth = d, n_estimators = 100),\n        RandomForestRegressor(max_depth = d, n_estimators = 100)\n    ]\n    #print('Max Depth =', d, '\\n')\n    \n    for r in regressors:\n        dtr = r\n        mdtr = MultiOutputRegressor(r)\n        mdtr.fit(X_train, y_train)\n        yhat = mdtr.predict(X_test)\n        this_rscore = r2_score(y_test, yhat, multioutput='uniform_average')\n        this_ev = explained_variance_score(y_test, yhat, multioutput = 'uniform_average')\n        \n        if (best_ev < this_ev):\n            best_model = mdtr\n            best_rscore = this_rscore\n            best_ev = this_ev"
        }, 
        {
            "source": "From the linear, decision tree and knn regressors, the following model predicted age demographics with the best r2_score and expected variance. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "MultiOutputRegressor(estimator=BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n       normalize=False, tol=0.001, verbose=False),\n           n_jobs=None) \n Num Estimators:  21 \n R2 Score:  0.42721179240614143 \n Explained Variance Score:  0.5226635220078892\n"
                }
            ], 
            "source": "print(best_model, '\\n',  'Num Estimators: ', len(best_model.estimators_), '\\n', 'R2 Score: ', best_rscore, '\\n', 'Explained Variance Score: ', best_ev)"
        }, 
        {
            "source": "#### Analysis\n\nThe two primary metrics I utilized to score and compare the performance of the estimators were explained variance and r squared score (coefficient of determination) because this problem is a regression problem and multioutput. Among the provided sklearn metrics, r2_score and explained_variance_score provide an objective measure of overall correlation. It is also important to note that I used the \"uniform_average\" parameter for both metrics because the venue data which I was able to obtain only included the 100 highest ranked venues for each neighborhood. With this lack of data, weighting venue categories differently would not be appropriate. \n\nThe best model in this experiment turned out to be a linear regression model known as Bayesian Ridge with 21 estimators (one for each label). The r squared score of the linear regressor measures how correlated the predicted demographic data is to the venue test data. The score of .43 implies that the demographic data is overall positively correlated to the 21 estimators and approximately 43% of the age demographics can be explained by the venue categories. The explained variance score measures how well the model explains the variance of the prediction compared to the variance of the training data so the score of approximately .52 indicates that a little over half of the variance in the prediction is explained by the variance in the training data. \n\nLet\u2019s use the first estimator as an example. It represents the age group 0-4 years and we can explore the coefficients associated with each venue category in order to understand how the model is predicting the relative change in this venue category versus an incremental increase in the age group. The table below shows the coefficients associated with each venue category sorted in descending order.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 49, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Model Intercept:  0.04771125072112635 \n Model Coefficients:  \n                       Category  Coefficient\n128  Latin American Restaurant     0.059177\n29                     Brewery     0.056856\n70         Egyptian Restaurant     0.052795\n75                        Farm     0.050198\n7             Asian Restaurant     0.041578\n"
                }
            ], 
            "source": "age_cat = 0\nsingle_label_coef = pd.DataFrame(list(zip(features.columns.tolist(), best_model.estimators_[age_cat].coef_)), \n               columns =['Category', 'Coefficient']).sort_values('Coefficient', ascending=False) \n\nprint('Model Intercept: ', best_model.estimators_[age_cat].intercept_, '\\n', 'Model Coefficients: ','\\n', single_label_coef.head(5))"
        }, 
        {
            "source": "### Clustering \nNext I will use a different approach to explored the relationship between venue categories and age demographics by using clustering algorithms. The algorithms will cluster the neighborhoods based on their demographic data then I will compare the venue categories in each cluster based on their frequency and novelty.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Estimated number of clusters: 14\n"
                }
            ], 
            "source": "from sklearn.cluster import AffinityPropagation\nfrom sklearn import metrics\n# Use labels because that is the most complete data set\n# Using Affinity Prop because dataset is small and to estimate number of clusters\ntoronto_affinity = AffinityPropagation().fit(norm_labels)\n\ncluster_centers_indices = toronto_affinity.cluster_centers_indices_\nalabels = toronto_affinity.labels_\n\nn_clusters = len(cluster_centers_indices)\n\nprint('Estimated number of clusters: %d' % n_clusters)"
        }, 
        {
            "source": "I leveraged the Affinity Propagation clustering algorithm to predict the appropriate number of clusters because this is a convenient feature of this particular clustering algorithm and since the dataset is small. I will then use the standard KMeans clustering to form the clusters and the following metrics to score the model (max score = 1). Homogeneity describes how well clusters contains only members of a single label. Completeness measures how well all members of a given label are assigned to the a particular cluster. V-measure represents the harmonic mean between homogeneity and completeness.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Homogeneity: 0.809\nCompleteness: 0.779\nV-measure: 0.794\n"
                }
            ], 
            "source": "from sklearn.cluster import KMeans\n\n# Advantages to using kmeans is that it scales better for larger datasets\n# 14 clusters provides perfect score on metrics\n# set number of clusters\nkclusters = n_clusters\n\n# cluster neighborhoods by age demographics\ntoronto_clusters = KMeans(n_clusters=kclusters, random_state=0).fit(norm_labels)\nklabels = toronto_clusters.labels_\n\n#Compare clustering models\nprint(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(alabels, klabels))\nprint(\"Completeness: %0.3f\" % metrics.completeness_score(alabels, klabels))\nprint(\"V-measure: %0.3f\" % metrics.v_measure_score(alabels, klabels))"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "demo_clusters = pd.DataFrame(data = norm_labels[0:,0:], columns=labels.columns)\ndemo_clusters['Labels'] = toronto_clusters.labels_\ndemo_clusters_sum = demo_clusters.groupby(by=['Labels']).sum()\n\n#Show which age groups had greatest occurance above mean in each cluster\n#for label in range(demo_clusters_sum.shape[0]):\n#    print(demo_clusters_sum.iloc[label, :].sort_values(ascending = False).head(5), '\\n')"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "venue_clusters = pd.DataFrame(data = norm_features[0:,0:], columns=features.columns)\nvenue_clusters['Labels'] = toronto_clusters.labels_\nvenue_clusters_sum = venue_clusters.groupby(by=['Labels']).sum()\n# Show which venues occured greatest above the mean\n#for label in range(demo_clusters_sum.shape[0]):\n#    print(venue_clusters_sum.iloc[label, :].sort_values(ascending = False).head(5), '\\n')"
        }, 
        {
            "source": "Clustering provides a novel approach to analyzing the relationship between labels and features. We can compare the most interesting labels and features for each cluster by displaying the ones which have the greatest occurance above their normalized mean. Let's examine the top two labels and four features for each cluster to see what trends may be apparent.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Index\n45 to 49 years    5.950862\n40 to 44 years    3.985381\nName: 0, dtype: float64 \n Pakistani Restaurant    6.563925\nEgyptian Restaurant     5.896619\nSoccer Field            4.657799\nEthiopian Restaurant    4.427110\nName: 0, dtype: float64 \n\nIndex\n30 to 34 years    15.346218\n35 to 39 years    13.681714\nName: 1, dtype: float64 \n Performing Arts Venue    14.459138\nSpanish Restaurant       13.639887\nArt Gallery              13.577657\nAquarium                 13.141043\nName: 1, dtype: float64 \n\nIndex\n70 to 74 years    6.865712\n65 to 69 years    6.173570\nName: 2, dtype: float64 \n Hookah Bar             8.966120\nSzechuan Restaurant    8.966120\nKorean Restaurant      7.441957\nWhisky Bar             6.788818\nName: 2, dtype: float64 \n\nIndex\n40 to 44 years    17.549786\n35 to 39 years    12.338174\nName: 3, dtype: float64 \n Circus                 16.426303\nIce Cream Shop         13.307757\nAmerican Restaurant    11.801167\nHistoric Site          11.579728\nName: 3, dtype: float64 \n\nIndex\n20 to 24 years    7.258659\n25 to 29 years    2.834215\nName: 4, dtype: float64 \n Spanish Restaurant    5.865151\nSandwich Place        5.457528\nShoe Store            5.053559\nArt Gallery           4.903043\nName: 4, dtype: float64 \n\nIndex\n40 to 44 years    4.332026\n55 to 59 years    3.308082\nName: 5, dtype: float64 \n Comfort Food Restaurant    11.157612\nSeafood Restaurant         11.000000\nGeneral Entertainment       7.844645\nFood Court                  7.732555\nName: 5, dtype: float64 \n\nIndex\n80 to 84 years    8.072958\n75 to 79 years    6.848061\nName: 6, dtype: float64 \n Leather Goods Store      10.596713\nFood Court                9.711358\nVietnamese Restaurant     9.602847\nAirport                   9.346852\nName: 6, dtype: float64 \n\nIndex\n25 to 29 years    3.967675\n30 to 34 years    3.825786\nName: 7, dtype: float64 \n Harbor / Marina       5.567764\nBasketball Stadium    4.795832\nSoccer Stadium        4.795832\nSalon / Barbershop    4.266146\nName: 7, dtype: float64 \n\nIndex\n75 to 79 years    17.401895\n80 to 84 years    17.097730\nName: 8, dtype: float64 \n Tattoo Parlor           15.423758\nCantonese Restaurant    13.007037\nHotpot Restaurant       12.299695\nNoodle House            11.231811\nName: 8, dtype: float64 \n\nIndex\n20 to 24 years    12.321712\n25 to 29 years     9.864172\nName: 9, dtype: float64 \n Comedy Club    11.730303\nShoe Store     10.107119\nMuseum          9.562717\nTheater         9.216354\nName: 9, dtype: float64 \n\nIndex\n0 to 4 years    4.079441\n5 to 9 years    3.375536\nName: 10, dtype: float64 \n Farm                   3.872983\nEgyptian Restaurant    3.109126\nComic Shop             2.913910\nSoccer Field           2.526780\nName: 10, dtype: float64 \n\nIndex\n60 to 64 years    13.869609\n55 to 59 years    13.349524\nName: 11, dtype: float64 \n Filipino Restaurant     12.252659\nSports Bar              10.733126\nHungarian Restaurant    10.688805\nPub                     10.425335\nName: 11, dtype: float64 \n\nIndex\n15 to 19 years    14.916461\n10 to 14 years    13.166303\nName: 12, dtype: float64 \n Jewelry Store                15.922193\nLatin American Restaurant    14.980712\nWarehouse Store              13.215492\nSmoothie Shop                12.909314\nName: 12, dtype: float64 \n\nIndex\n100 years and over    15.301624\n95 to 99 years        15.029382\nName: 13, dtype: float64 \n Event Space          7.146183\nDeli / Bodega        6.955772\nRecreation Center    6.708204\nFlower Shop          6.662501\nName: 13, dtype: float64 \n\n"
                }
            ], 
            "source": "for label in range(demo_clusters_sum.shape[0]):     \n    print((demo_clusters_sum.iloc[label, :]).sort_values(ascending = False).head(2),'\\n', \n          venue_clusters_sum.iloc[label, venue_clusters_sum.columns != 'Labels'].sort_values(ascending = False).head(4),'\\n')"
        }, 
        {
            "source": "### Results\n\nAfter finding wide variations in the results of the same model re-training on the data multiple times, I investigated the venue data collection and found that by adding and setting the parameters of time/day to any in the search method then I could achieve a more consistent venue profile for each neighborhood. Despite the deficits in the supply of data, several of the models performed surprisingly well.\n\nThe Bayesian Ridge linear regressor in particular was able to explain about 43% of the local demographic data based on the local venue category data. In the sample table examining the model coefficients for the age group 0-4 years, the highest positively weighted venue categories were Latin American Restaurant, Brewery, Egyptian Restaurant and Farm. Some other relationships which occured in this model were that the gym and athletic venues are more popular among the ages 20 - 34 and the BBQ Joint ranking #1 between the ages 45-74 and then is gradually replaced by asian and mediterrainian restaurants. \n\nThe clustering model seemed to favor grouping people who are close in age together rather than more diverse combitnations which is what you might expect if certain venue categories' appeal greatest to a particular age group and then gradually appeal less to people older or younger than that group following a distribution. To support the findings for the age group in the linear regressor for group 0-4 years the clustering model also found the Farm and Egyptian Restaurant were assosicated with the groups 0-4 and 5-9 years. The Latin American Restaurant was assosciated with the 10-14 and 15-19 years groups and the Brewery was not associated with younger age goups in the cluster model. The clustering model also presented cluster with dominate 10 year range age groups and assosciated with specific venue categories which overlap those seen in the linear regressor. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Discussion\n\nThis exploratory study provides lots of space for further discussion and exploration. Due to the small sample size of only 96 neighborhoods and the large number of demographic and venue categories (21 and 226 respectively), it is difficult to train a robust or generalized model on such a small yet diverse dataset. It is also important to note that there are a limited number of regression models available that are compatible with the multioutput extension compared to the models available for single output regression or classification problems. It would of course be useful to include more cities and larger venue category datasets in a future study but given the results from this small study some useful observations can still be made. \n\nThe relationship between the demographic and venue data can be more nuanced. For example, when examining the Bayesian Ridge regression model the estimator coefficients for the age group 0-4 show venues that might not be intuitively associated with young children such as Brewery or the ethnic restaurants. One possible explanation is that the children are not the ones using these venues but perhaps their parents are. This appeared to be true for the ethnic restaurants but in the case of the brewery, it only appeared highly associated with the 0-4 and 5-9 age groups. There were 150 Breweries included in the venue data which means that it was not simply an outlier case.\n\nThe clustering model provided a novel perspective of the relationship by associating some new venue categories with different age groups such as Comedy Club associated with people in their 20s, Performing Arts Venue for people in their 30s and Sports Venues for people in both age groups. The Circus is a big attraction for people in their early 40s and various Asian cuisine restaurants are highly associated with people over 60 years old. Some of these findings are also supported in the linear regression model. The Comedy Club was weighted highly for people in their late 20s and the Circus was weighted heavily for people in their early 40s. The linear regressor also supports the trend of Asian cuisine restaurants being popular with older adults.\n\nOne distinct type of venue category that is highly associated to many different age groups is restaurants of various cuisines. Given how ethnically diverse the city of Toronto is, it's useful to examine its history of population growth and influxes of immigration from different ethnic populations at different periods in time. How long ago an influx of a particular Ethinic population occured may explain the popularity of the respective cuisine with the current age of those patrons. Understanding the importance of historic demographic changes for the city of Toronto may be useful for Toronto but may not be consistent across other cities in Canada or even less consistent with other countries. Consequently, even though different types of restaurants are highly associated with different age groups, they may not generalize well and perhaps should be merged into broader categories or simply as restaurants in order to pursue a model which could be applied more generally. This same rationale could be used to combine other venue categories into broader venue categories thus significantly shrinking the total number of feature categories especially if the neighborhood sample size is small.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Conclusion", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The purpose of this case study was primarily exploratory with the goal to understand novel approaches to improve methodologies for building demographic maps. Several different machine learning techniques were utilized to predict neighborhood age demographic data based on venue category data in the city of Toronto in order to better understand the relationship between the two. For this type of multioutput regression problem it seems that a linear regression model such as Bayesian Ridge may produce estimators with the highest prediction efficacy. The clustering approach reveals novel associations as well as supporting findings from the regression model making the two approaches complementary for this type of problem.\n\nWhile the regression and clustering approaches can be mutually beneficial for modeling local demographics based on local venues, there are still unique local patterns of venues that can arise in response to historic, ethnic and other factors affecting the local population. In order to achieve a model which can be well generalized for predicting age demographics in different cities, forming broader venue categories may be useful to overcome the unique local differences. This study has demonstrated that valuable insight into local age demographics can be gained from local venue data and combined with the techniques described in this study can help improve the overall methodology for constructing demographic maps.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "*For questions of comments please follow up at adahlstromcg@gmail.com*", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}