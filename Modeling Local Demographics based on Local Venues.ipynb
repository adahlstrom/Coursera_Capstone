{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modeling Local Demographics based on Local Venues in Toronto, Canada", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "*By Andrew Dahlstrom*\n\n*10/04/2019*", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Introduction\n\nThis Notebook is my submission for the final project in the IBM Applied Data Science Capstone Course. This assignment requires that I design an imagined scenario which will allow me to demonstrate the techniques and methodologies I have learned in the IBM Applied Data Science Specialization program as well as utilize the FourSquare API and the scikit-learn library for learning algorithms in Python. The scenario I devised for this project is that I have been contracted by International Health Organization to conduct an exploratory case with the goal to improve methodologies for building demographic maps. To accomplish this goal, I have chosen to experiment with modeling and predicting local demographics based on local venue data for neighborhoods in the city of Toronto, Canada. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Background\n\nPopulation demographic maps are useful tools for many humanitarian efforts including to manage disease outbreaks, water scarcity, disaster relief efforts, electrical grid expansion, expansion of health or education services etc. Demographic data is not always readily available in some areas so any contribution to methodology that can improve the accuracy of population maps could be useful to humanitarian efforts. The goal of this project is to explore how accurately local venue data can predict the demographic data for that neighborhood (organized by postal code) using relevant machine learning techniques to create a prediction model. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Data\n\nThis city of Toronto was selected because of the detailed and recent demographic data available publicly and the large collection of venue data available for each neighborhood. The data for this project has been collected from the following sources:\n\n* Toronto postal code data can be found on [Wikipedia](https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M).\n* The demographic data for Toronto has been collected from the [2016 Census](https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/pd-pl/Table.cfm?Lang=Eng&T=1201&S=22&O=A).\n* The local venue data will be retrieved from the [FourSquare API](https://developer.foursquare.com/).\n* Latitude and longitude geospatial data for postal codes provided by IBM course website", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Construct Dataframes\nThe first step is to create a dataframe of postal codes for the city of Toronto using a web scraper in order to organize the venue and demographic data into smaller communities.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from bs4 import BeautifulSoup\nimport requests\nimport numpy as np\nimport pandas as pd"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M3A</td>\n      <td>North York</td>\n      <td>Parkwoods</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M4A</td>\n      <td>North York</td>\n      <td>Victoria Village</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Harbourfront</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Regent Park</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M6A</td>\n      <td>North York</td>\n      <td>Lawrence Heights</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code           Borough      Neighborhood\n0         M3A        North York         Parkwoods\n1         M4A        North York  Victoria Village\n2         M5A  Downtown Toronto      Harbourfront\n3         M5A  Downtown Toronto       Regent Park\n4         M6A        North York  Lawrence Heights"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Scrape text from wikitable online and load into a Pandas data frame\n\nsource = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\nsoup = BeautifulSoup(source, 'lxml')\n#print(soup.prettify())\n\nfor table in soup.find_all('table', class_= 'wikitable'):\n    neightable = []\n    \n    for row in table.find_all('tr'):\n        neighrow = []\n        \n        for data in row.find_all('td'):\n            neighrow.append(data.text.rstrip('\\n'))\n        \n        neightable.append(neighrow)\n\n#Clean data remove unassigned boroughs\n\nneighdf = pd.DataFrame(neightable, columns = ['Postal Code', 'Borough', 'Neighborhood'])\nneighdf.drop(index=0, inplace=True)\ntodrop = neighdf[neighdf['Borough'] == \"Not assigned\"].index\nneighdf.drop(todrop, inplace=True)\nneighdf.reset_index(drop=True).head(5)"
        }, 
        {
            "source": "In order to clean the Toronto postal code data we need to merge neighborhoods that share the same postal code and give unnamed neighbourhoods the name of their borough.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Rouge, Malvern</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>Scarborough</td>\n      <td>Highland Creek, Rouge Hill, Port Union</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>Scarborough</td>\n      <td>Guildwood, Morningside, West Hill</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>Scarborough</td>\n      <td>Woburn</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>Scarborough</td>\n      <td>Cedarbrae</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code      Borough                            Neighborhood\n0         M1B  Scarborough                          Rouge, Malvern\n1         M1C  Scarborough  Highland Creek, Rouge Hill, Port Union\n2         M1E  Scarborough       Guildwood, Morningside, West Hill\n3         M1G  Scarborough                                  Woburn\n4         M1H  Scarborough                               Cedarbrae"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Replace unassigned neighborhoods or neighborhoods with incorrect names with their borough name \n\nfor index, row in neighdf.iterrows(): \n    s = neighdf.at[index, 'Neighborhood']\n    if  s == \"Not assigned\" or len(s.split()) > 4 :\n        neighdf.at[index, 'Neighborhood'] = neighdf.at[index, 'Borough']\n\n# Merge neighborhoods with same postalcode\n\nneighdf = neighdf.groupby(['Postal Code','Borough'])['Neighborhood'].apply(', '.join).reset_index()\nneighdf.head(5)       "
        }, 
        {
            "source": "Next we need to get the csv file from the link provided in the course website to get the latitude and longitude coordinates for each postal code.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>43.806686</td>\n      <td>-79.194353</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>43.784535</td>\n      <td>-79.160497</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>43.763573</td>\n      <td>-79.188711</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>43.770992</td>\n      <td>-79.216917</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>43.773136</td>\n      <td>-79.239476</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code   Latitude  Longitude\n0         M1B  43.806686 -79.194353\n1         M1C  43.784535 -79.160497\n2         M1E  43.763573 -79.188711\n3         M1G  43.770992 -79.216917\n4         M1H  43.773136 -79.239476"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import io\ngeourl=\"http://cocl.us/Geospatial_data\"\ns = requests.get(geourl).content\ngeodata = pd.read_csv(io.StringIO(s.decode('utf-8')))\ngeodata.head(5)"
        }, 
        {
            "source": "Add latitude and longitude data to neighborhood dataframe.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(103, 5)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "for index, row in neighdf.iterrows():   \n    for i, r in geodata.iterrows():\n        if neighdf.at[index, 'Postal Code'] == geodata.at[i, 'Postal Code']:\n            neighdf.at[index, 'Latitude'] = geodata.at[i, 'Latitude']\n            neighdf.at[index, 'Longitude'] = geodata.at[i, 'Longitude']\n\nneighdf.shape"
        }, 
        {
            "source": "Next we need the FourSquare API to get the venue data for each postal code.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "### Create dataframe containing venue data for each postal code ###\n\n# Define function to get venue data for each postal code.\n# Takes as an argument location name, latitude and logitude coordinates\n# returns a dataframe containing venue data for the nearest \n# LIMIT number of venues within the radius\n\n# Max number of venues within radius\nLIMIT = 100\n\ndef getNearbyVenues(names, latitudes, longitudes, radius=8000):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius,\n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n        nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n        nearby_venues.columns = ['Postal Code', \n                  'Postal Code Latitude', \n                  'Postal Code Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 31, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(10300, 7)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Create the dataframe using the getNearbyVenues function\n\nvenues = getNearbyVenues(names=neighdf['Postal Code'],\n                                 latitudes=neighdf['Latitude'],\n                                 longitudes=neighdf['Longitude'],\n                                )\n\nvenues.shape"
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "There are 219 unique venue categories and the following venue counts for each postal code...\n"
                }, 
                {
                    "execution_count": 32, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code Latitude</th>\n      <th>Postal Code Longitude</th>\n      <th>Venue</th>\n      <th>Venue Latitude</th>\n      <th>Venue Longitude</th>\n      <th>Venue Category</th>\n    </tr>\n    <tr>\n      <th>Postal Code</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>M1B</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1C</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1E</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1G</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>M1H</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "             Postal Code Latitude  Postal Code Longitude  Venue  \\\nPostal Code                                                       \nM1B                           100                    100    100   \nM1C                           100                    100    100   \nM1E                           100                    100    100   \nM1G                           100                    100    100   \nM1H                           100                    100    100   \n\n             Venue Latitude  Venue Longitude  Venue Category  \nPostal Code                                                   \nM1B                     100              100             100  \nM1C                     100              100             100  \nM1E                     100              100             100  \nM1G                     100              100             100  \nM1H                     100              100             100  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "print('There are {} unique venue categories and the following venue counts for each postal code...'.format(len(venues['Venue Category'].unique())))\nvenues.groupby('Postal Code').count().head(5)"
        }, 
        {
            "source": "Now that we have the venue data, the next step is to build the dataframe of community venue profiles for each postal code based on the venue data. I will use a method called one hot encoding to build a binary classification table which can then be used to build a frequency table for the occurences of a venue in each category for each postal code. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 39, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Afghan Restaurant</th>\n      <th>Airport</th>\n      <th>Airport Lounge</th>\n      <th>American Restaurant</th>\n      <th>Aquarium</th>\n      <th>Art Gallery</th>\n      <th>Arts &amp; Crafts Store</th>\n      <th>Asian Restaurant</th>\n      <th>Athletics &amp; Sports</th>\n      <th>...</th>\n      <th>Vegetarian / Vegan Restaurant</th>\n      <th>Vietnamese Restaurant</th>\n      <th>Warehouse Store</th>\n      <th>Whisky Bar</th>\n      <th>Wine Bar</th>\n      <th>Wings Joint</th>\n      <th>Women's Store</th>\n      <th>Yoga Studio</th>\n      <th>Zoo</th>\n      <th>Zoo Exhibit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 220 columns</p>\n</div>", 
                        "text/plain": "  Postal Code  Afghan Restaurant  Airport  Airport Lounge  \\\n0         M1B                0.0      0.0             0.0   \n1         M1C                0.0      0.0             0.0   \n2         M1E                0.0      0.0             0.0   \n3         M1G                0.0      0.0             0.0   \n4         M1H                0.0      0.0             0.0   \n\n   American Restaurant  Aquarium  Art Gallery  Arts & Crafts Store  \\\n0                 0.00       0.0          0.0                 0.01   \n1                 0.01       0.0          0.0                 0.00   \n2                 0.00       0.0          0.0                 0.01   \n3                 0.00       0.0          0.0                 0.01   \n4                 0.00       0.0          0.0                 0.01   \n\n   Asian Restaurant  Athletics & Sports  ...  Vegetarian / Vegan Restaurant  \\\n0              0.01                0.01  ...                            0.0   \n1              0.00                0.01  ...                            0.0   \n2              0.02                0.01  ...                            0.0   \n3              0.02                0.01  ...                            0.0   \n4              0.02                0.01  ...                            0.0   \n\n   Vietnamese Restaurant  Warehouse Store  Whisky Bar  Wine Bar  Wings Joint  \\\n0                   0.00             0.01         0.0       0.0         0.01   \n1                   0.00             0.00         0.0       0.0         0.01   \n2                   0.00             0.00         0.0       0.0         0.00   \n3                   0.01             0.01         0.0       0.0         0.00   \n4                   0.01             0.01         0.0       0.0         0.00   \n\n   Women's Store  Yoga Studio   Zoo  Zoo Exhibit  \n0            0.0          0.0  0.02         0.10  \n1            0.0          0.0  0.02         0.10  \n2            0.0          0.0  0.02         0.09  \n3            0.0          0.0  0.02         0.05  \n4            0.0          0.0  0.02         0.01  \n\n[5 rows x 220 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# One hot encoding\ntoronto_onehot = pd.get_dummies(venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# Add back in postal code column and move it to front\ntoronto_onehot['Postal Code'] = venues['Postal Code']\nfixed_columns = list(toronto_onehot)\nfixed_columns.insert(1, fixed_columns.pop(\n    fixed_columns.index('Postal Code')))\ntoronto_onehot = toronto_onehot.loc[:, fixed_columns]\n\n# Build frequency table by postal code and by taking the mean of the frequency of occurrence for each category\ntoronto_venues = toronto_onehot.groupby('Postal Code').mean().reset_index()\ntoronto_venues.head(5)"
        }, 
        {
            "source": "Now that the neighborhood venue profile dataframe is complete, the next step is to build the neighborhood demographics profile dataframe using data from the 2016 Canada Census.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 40, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postal Code</th>\n      <th>Index</th>\n      <th>Population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>Total - Age</td>\n      <td>66110.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1B</td>\n      <td>0 to 14 years</td>\n      <td>11535.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1B</td>\n      <td>0 to 4 years</td>\n      <td>3540.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1B</td>\n      <td>Under 1 year</td>\n      <td>675.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1B</td>\n      <td>1</td>\n      <td>705.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  Postal Code          Index  Population\n0         M1B    Total - Age     66110.0\n1         M1B  0 to 14 years     11535.0\n2         M1B   0 to 4 years      3540.0\n3         M1B   Under 1 year       675.0\n4         M1B              1       705.0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from zipfile import ZipFile\n\n# Get demographic data from Canada Census website, load into dataframe\nurl = \"https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/dt-td/CompDataDownload.cfm?LANG=E&PID=109790&OFT=CSV\"\nr = requests.get(url)\nz = ZipFile(io.BytesIO(r.content))\nz.extractall()\n\ndemo = pd.read_csv(z.open('98-400-X2016008_English_CSV_data.csv'), \n                     usecols = ['L9Z', 'Average age', '50.0'],\n                     sep = ',', skiprows = 112395, nrows = 12192)\ndemo.rename(columns = {\"L9Z\": \"Postal Code\", \"Average age\": \"Index\", \n                       \"50.0\" : \"Population\"}, inplace = True)\ndemo.head()"
        }, 
        {
            "source": "Next let's organize the table so that the index is postal codes and the columns are population per age groups in increments of 5 years.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 41, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Index</th>\n      <th>Postal Code</th>\n      <th>0 to 4 years</th>\n      <th>5 to 9 years</th>\n      <th>10 to 14 years</th>\n      <th>15 to 19 years</th>\n      <th>20 to 24 years</th>\n      <th>25 to 29 years</th>\n      <th>30 to 34 years</th>\n      <th>35 to 39 years</th>\n      <th>40 to 44 years</th>\n      <th>...</th>\n      <th>55 to 59 years</th>\n      <th>60 to 64 years</th>\n      <th>65 to 69 years</th>\n      <th>70 to 74 years</th>\n      <th>75 to 79 years</th>\n      <th>80 to 84 years</th>\n      <th>85 to 89 years</th>\n      <th>90 to 94 years</th>\n      <th>95 to 99 years</th>\n      <th>100 years and over</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M1B</td>\n      <td>3540.0</td>\n      <td>3920.0</td>\n      <td>4080.0</td>\n      <td>4680.0</td>\n      <td>5090.0</td>\n      <td>4835.0</td>\n      <td>4415.0</td>\n      <td>3950.0</td>\n      <td>4150.0</td>\n      <td>...</td>\n      <td>4570.0</td>\n      <td>4070.0</td>\n      <td>3615.0</td>\n      <td>2470.0</td>\n      <td>1610.0</td>\n      <td>925.0</td>\n      <td>530.0</td>\n      <td>220.0</td>\n      <td>65.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M1C</td>\n      <td>1575.0</td>\n      <td>1760.0</td>\n      <td>1905.0</td>\n      <td>2380.0</td>\n      <td>2695.0</td>\n      <td>2130.0</td>\n      <td>1870.0</td>\n      <td>1955.0</td>\n      <td>1965.0</td>\n      <td>...</td>\n      <td>2970.0</td>\n      <td>2670.0</td>\n      <td>2340.0</td>\n      <td>1695.0</td>\n      <td>1090.0</td>\n      <td>665.0</td>\n      <td>385.0</td>\n      <td>185.0</td>\n      <td>40.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M1E</td>\n      <td>2405.0</td>\n      <td>2585.0</td>\n      <td>2585.0</td>\n      <td>3100.0</td>\n      <td>3450.0</td>\n      <td>2975.0</td>\n      <td>2665.0</td>\n      <td>2550.0</td>\n      <td>2720.0</td>\n      <td>...</td>\n      <td>3610.0</td>\n      <td>3050.0</td>\n      <td>2370.0</td>\n      <td>1840.0</td>\n      <td>1545.0</td>\n      <td>1195.0</td>\n      <td>840.0</td>\n      <td>405.0</td>\n      <td>105.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M1G</td>\n      <td>1720.0</td>\n      <td>1925.0</td>\n      <td>1950.0</td>\n      <td>2140.0</td>\n      <td>2350.0</td>\n      <td>2125.0</td>\n      <td>1835.0</td>\n      <td>1810.0</td>\n      <td>1775.0</td>\n      <td>...</td>\n      <td>1970.0</td>\n      <td>1530.0</td>\n      <td>1320.0</td>\n      <td>1015.0</td>\n      <td>925.0</td>\n      <td>685.0</td>\n      <td>370.0</td>\n      <td>140.0</td>\n      <td>20.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M1H</td>\n      <td>1330.0</td>\n      <td>1365.0</td>\n      <td>1175.0</td>\n      <td>1320.0</td>\n      <td>1970.0</td>\n      <td>2000.0</td>\n      <td>1910.0</td>\n      <td>1705.0</td>\n      <td>1540.0</td>\n      <td>...</td>\n      <td>1605.0</td>\n      <td>1340.0</td>\n      <td>1010.0</td>\n      <td>820.0</td>\n      <td>670.0</td>\n      <td>655.0</td>\n      <td>385.0</td>\n      <td>185.0</td>\n      <td>35.0</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 22 columns</p>\n</div>", 
                        "text/plain": "Index Postal Code  0 to 4 years  5 to 9 years  10 to 14 years  15 to 19 years  \\\n0             M1B        3540.0        3920.0          4080.0          4680.0   \n1             M1C        1575.0        1760.0          1905.0          2380.0   \n2             M1E        2405.0        2585.0          2585.0          3100.0   \n3             M1G        1720.0        1925.0          1950.0          2140.0   \n4             M1H        1330.0        1365.0          1175.0          1320.0   \n\nIndex  20 to 24 years  25 to 29 years  30 to 34 years  35 to 39 years  \\\n0              5090.0          4835.0          4415.0          3950.0   \n1              2695.0          2130.0          1870.0          1955.0   \n2              3450.0          2975.0          2665.0          2550.0   \n3              2350.0          2125.0          1835.0          1810.0   \n4              1970.0          2000.0          1910.0          1705.0   \n\nIndex  40 to 44 years  ...  55 to 59 years  60 to 64 years  65 to 69 years  \\\n0              4150.0  ...          4570.0          4070.0          3615.0   \n1              1965.0  ...          2970.0          2670.0          2340.0   \n2              2720.0  ...          3610.0          3050.0          2370.0   \n3              1775.0  ...          1970.0          1530.0          1320.0   \n4              1540.0  ...          1605.0          1340.0          1010.0   \n\nIndex  70 to 74 years  75 to 79 years  80 to 84 years  85 to 89 years  \\\n0              2470.0          1610.0           925.0           530.0   \n1              1695.0          1090.0           665.0           385.0   \n2              1840.0          1545.0          1195.0           840.0   \n3              1015.0           925.0           685.0           370.0   \n4               820.0           670.0           655.0           385.0   \n\nIndex  90 to 94 years  95 to 99 years  100 years and over  \n0               220.0            65.0                10.0  \n1               185.0            40.0                 5.0  \n2               405.0           105.0                15.0  \n3               140.0            20.0                 5.0  \n4               185.0            35.0                 5.0  \n\n[5 rows x 22 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "toronto_demo = demo.pivot(index = 'Postal Code', columns = 'Index', values = 'Population')\nkeep_columns = ['0 to 4 years', '5 to 9 years', '10 to 14 years', '15 to 19 years', \n                '20 to 24 years', '25 to 29 years', '30 to 34 years', '35 to 39 years',\n                '40 to 44 years', '45 to 49 years', '50 to 54 years', '55 to 59 years',\n                '60 to 64 years', '65 to 69 years', '70 to 74 years', '75 to 79 years',\n                '80 to 84 years', '85 to 89 years', '90 to 94 years', '95 to 99 years',\n                '100 years and over']\ntoronto_demo = toronto_demo[keep_columns].reset_index()\ntoronto_demo.head()"
        }, 
        {
            "source": "#### Notes about the data: \n\n* The demographic data comes from a 2016 census but the venue data is current meaning that the demographic data is lagging behind the venue data by a couple of years so this will affect the accuracy of the model.\n* For financial reasons I must limit the number of venues I am able to collect data on for each neighborhood. I will therefore find the distribution of the venues for each category within each neighborhood in order to create a venue profile for each neighborhood.  \n* I will be exploring how well venue data predicts the age distribution of the population in each neighborhood separated into 5 year increments.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Methodology\nNow it's time for the exciting part! First I will test different machine learning regression algorithms from the sklearn package to fit the venue data then analyze which model is best at predicting neighborhood age demographics. Second, I will take a different approach to understanding the relationship between dataframes by utilizing clustering techniques to look for trends between venues and age demographics. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Preprocess Data\nFirst we can normalize our data by finding the mean for each category and then subtracting that from the mean of each postal code. This will make it easier to notice differences between the neighborhoods. We can also use sklearn built in preprocessing to normalize our labels and features with the StandardScaler.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 42, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(96, 219)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from sklearn.preprocessing import StandardScaler\nfeatures_scaler = StandardScaler()\n\nfeatures = toronto_venues\n\n# Drop the rows in the features set that we do not have population data for\nrowsDrop = list(set(toronto_venues['Postal Code']).symmetric_difference(set(toronto_demo['Postal Code'])))\nfeatures.drop(features.loc[features['Postal Code'].isin(rowsDrop)].index, inplace=True)\n\n# Drop Postal Code column to have all numeric\nfeatures.drop(['Postal Code'], axis = 1, inplace = True)\nfeatures.shape"
        }, 
        {
            "execution_count": 43, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 43, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Index</th>\n      <th>0 to 4 years</th>\n      <th>5 to 9 years</th>\n      <th>10 to 14 years</th>\n      <th>15 to 19 years</th>\n      <th>20 to 24 years</th>\n      <th>25 to 29 years</th>\n      <th>30 to 34 years</th>\n      <th>35 to 39 years</th>\n      <th>40 to 44 years</th>\n      <th>45 to 49 years</th>\n      <th>...</th>\n      <th>55 to 59 years</th>\n      <th>60 to 64 years</th>\n      <th>65 to 69 years</th>\n      <th>70 to 74 years</th>\n      <th>75 to 79 years</th>\n      <th>80 to 84 years</th>\n      <th>85 to 89 years</th>\n      <th>90 to 94 years</th>\n      <th>95 to 99 years</th>\n      <th>100 years and over</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.053547</td>\n      <td>0.059295</td>\n      <td>0.061715</td>\n      <td>0.070791</td>\n      <td>0.076993</td>\n      <td>0.073136</td>\n      <td>0.066783</td>\n      <td>0.059749</td>\n      <td>0.062774</td>\n      <td>0.066707</td>\n      <td>...</td>\n      <td>0.069127</td>\n      <td>0.061564</td>\n      <td>0.054682</td>\n      <td>0.037362</td>\n      <td>0.024353</td>\n      <td>0.013992</td>\n      <td>0.008017</td>\n      <td>0.003328</td>\n      <td>0.000983</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.044204</td>\n      <td>0.049397</td>\n      <td>0.053466</td>\n      <td>0.066798</td>\n      <td>0.075639</td>\n      <td>0.059781</td>\n      <td>0.052484</td>\n      <td>0.054869</td>\n      <td>0.055150</td>\n      <td>0.067078</td>\n      <td>...</td>\n      <td>0.083357</td>\n      <td>0.074937</td>\n      <td>0.065675</td>\n      <td>0.047572</td>\n      <td>0.030592</td>\n      <td>0.018664</td>\n      <td>0.010806</td>\n      <td>0.005192</td>\n      <td>0.001123</td>\n      <td>0.000140</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.051219</td>\n      <td>0.055053</td>\n      <td>0.055053</td>\n      <td>0.066021</td>\n      <td>0.073475</td>\n      <td>0.063359</td>\n      <td>0.056756</td>\n      <td>0.054307</td>\n      <td>0.057928</td>\n      <td>0.069002</td>\n      <td>...</td>\n      <td>0.076882</td>\n      <td>0.064956</td>\n      <td>0.050474</td>\n      <td>0.039186</td>\n      <td>0.032904</td>\n      <td>0.025450</td>\n      <td>0.017889</td>\n      <td>0.008625</td>\n      <td>0.002236</td>\n      <td>0.000319</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.057932</td>\n      <td>0.064837</td>\n      <td>0.065679</td>\n      <td>0.072078</td>\n      <td>0.079151</td>\n      <td>0.071573</td>\n      <td>0.061805</td>\n      <td>0.060963</td>\n      <td>0.059784</td>\n      <td>0.065173</td>\n      <td>...</td>\n      <td>0.066352</td>\n      <td>0.051533</td>\n      <td>0.044459</td>\n      <td>0.034187</td>\n      <td>0.031155</td>\n      <td>0.023072</td>\n      <td>0.012462</td>\n      <td>0.004715</td>\n      <td>0.000674</td>\n      <td>0.000168</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.054508</td>\n      <td>0.055943</td>\n      <td>0.048156</td>\n      <td>0.054098</td>\n      <td>0.080738</td>\n      <td>0.081967</td>\n      <td>0.078279</td>\n      <td>0.069877</td>\n      <td>0.063115</td>\n      <td>0.068033</td>\n      <td>...</td>\n      <td>0.065779</td>\n      <td>0.054918</td>\n      <td>0.041393</td>\n      <td>0.033607</td>\n      <td>0.027459</td>\n      <td>0.026844</td>\n      <td>0.015779</td>\n      <td>0.007582</td>\n      <td>0.001434</td>\n      <td>0.000205</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 21 columns</p>\n</div>", 
                        "text/plain": "Index  0 to 4 years  5 to 9 years  10 to 14 years  15 to 19 years  \\\n0          0.053547      0.059295        0.061715        0.070791   \n1          0.044204      0.049397        0.053466        0.066798   \n2          0.051219      0.055053        0.055053        0.066021   \n3          0.057932      0.064837        0.065679        0.072078   \n4          0.054508      0.055943        0.048156        0.054098   \n\nIndex  20 to 24 years  25 to 29 years  30 to 34 years  35 to 39 years  \\\n0            0.076993        0.073136        0.066783        0.059749   \n1            0.075639        0.059781        0.052484        0.054869   \n2            0.073475        0.063359        0.056756        0.054307   \n3            0.079151        0.071573        0.061805        0.060963   \n4            0.080738        0.081967        0.078279        0.069877   \n\nIndex  40 to 44 years  45 to 49 years  ...  55 to 59 years  60 to 64 years  \\\n0            0.062774        0.066707  ...        0.069127        0.061564   \n1            0.055150        0.067078  ...        0.083357        0.074937   \n2            0.057928        0.069002  ...        0.076882        0.064956   \n3            0.059784        0.065173  ...        0.066352        0.051533   \n4            0.063115        0.068033  ...        0.065779        0.054918   \n\nIndex  65 to 69 years  70 to 74 years  75 to 79 years  80 to 84 years  \\\n0            0.054682        0.037362        0.024353        0.013992   \n1            0.065675        0.047572        0.030592        0.018664   \n2            0.050474        0.039186        0.032904        0.025450   \n3            0.044459        0.034187        0.031155        0.023072   \n4            0.041393        0.033607        0.027459        0.026844   \n\nIndex  85 to 89 years  90 to 94 years  95 to 99 years  100 years and over  \n0            0.008017        0.003328        0.000983            0.000151  \n1            0.010806        0.005192        0.001123            0.000140  \n2            0.017889        0.008625        0.002236            0.000319  \n3            0.012462        0.004715        0.000674            0.000168  \n4            0.015779        0.007582        0.001434            0.000205  \n\n[5 rows x 21 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "labels_scaler = StandardScaler()\n\nlabels = toronto_demo\nlabels.drop(['Postal Code'], axis = 1, inplace = True)\nlabels = toronto_demo.apply(lambda x: x / x.sum(), axis = 1)\nlabels.head()"
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "norm_features = features_scaler.fit_transform(features)\nnorm_labels = labels_scaler.fit_transform(labels)"
        }, 
        {
            "source": "#### Split the Data into Training and Testing Sets:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train set: (76, 219) (76, 21)\nTest set: (20, 219) (20, 21)\n"
                }
            ], 
            "source": "from sklearn.model_selection import train_test_split\n\n#Split the training data into a training and testing set\n#Note the switch between features and labels\nX_train, X_test, y_train, y_test = train_test_split(norm_features, norm_labels, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)"
        }, 
        {
            "source": "#### Find the best Regression Model :", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 50, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "from sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn import neighbors \n\nbest_rscore = 0\nbest_model = 0\nbest_ev = 0\n\nregressors = [\n    #Linear regressors \n    #linear_model.LinearRegression(),\n    #linear_model.SGDRegressor(),\n    linear_model.BayesianRidge(),\n    #linear_model.LassoLars(),\n    #linear_model.PassiveAggressiveRegressor(),\n    #linear_model.TheilSenRegressor(),\n    \n    #KNN regressors\n    #neighbors.KNeighborsRegressor(),\n    #neighbors.RadiusNeighborsRegressor()\n    ]\n\nfor r in regressors:\n    mr =  MultiOutputRegressor(r)\n    mr.fit(X_train, y_train)\n    yhat = mr.predict(X_test)\n    this_rscore = r2_score(y_test, yhat, multioutput='uniform_average')\n    this_ev = explained_variance_score(y_test, yhat, multioutput = 'uniform_average')\n    \n    if (best_rscore < this_rscore) :\n        best_model = mr\n        best_rscore = this_rscore\n        best_ev = this_ev"
        }, 
        {
            "execution_count": 51, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfor d in range(1, 5):\n\n    regressors = [\n        DecisionTreeRegressor(max_depth = d),\n        ExtraTreesRegressor(max_depth = d, n_estimators = 100),\n        RandomForestRegressor(max_depth = d, n_estimators = 100)\n    ]\n    #print('Max Depth =', d, '\\n')\n    \n    for r in regressors:\n        dtr = r\n        mdtr = MultiOutputRegressor(r)\n        mdtr.fit(X_train, y_train)\n        yhat = mdtr.predict(X_test)\n        this_rscore = r2_score(y_test, yhat, multioutput='uniform_average')\n        this_ev = explained_variance_score(y_test, yhat, multioutput = 'uniform_average')\n        \n        if (best_rscore < this_rscore):\n            best_model = mdtr\n            best_rscore = this_rscore\n            best_ev = this_ev"
        }, 
        {
            "source": "From the linear, decision tree and knn regressors, the following model predicted age demographics with the best r2_score and expected variance. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 53, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "MultiOutputRegressor(estimator=BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n       normalize=False, tol=0.001, verbose=False),\n           n_jobs=None) \n Num Estimators:  21 \n R2 Score:  0.4502172465213065 \n Explained Variance Score:  0.5293373878460669\n"
                }
            ], 
            "source": "print(best_model, '\\n',  'Num Estimators: ', len(best_model.estimators_), '\\n', 'R2 Score: ', best_rscore, '\\n', 'Explained Variance Score: ', best_ev)"
        }, 
        {
            "source": "#### Analysis\n\nThe two primary metrics I utilized to score and compare the performance of the estimators were explained variance and r2 score (coefficient of determination) because this problem is a regression problem and multilabel in nature. Therefore among the provided sklearn metrics, r2_score and explained_variance_score provide an objective measure of overall correlation. It is also important to note that I chose the \"uniform_average\" parameter for both metrics because the venue data which I was able to obtain only included  100 highest ranked venues for each neighborhood so with this lack of data weighting venue categories differently would not be appropriate. \n\nThe best model in this experiment turned out to be a linear regression model known as Bayesian Ridge with 21 estimators (one for each label). The r squared score of the linear regressor measures how correlated the predicted demographic data is to the venue test data. The score of .46 implies that the demographic data is overall positively correlated to the 21 estimators and approximately 46% of the age demographics can be explained by the venue categories. The explained variance score measures how well the model explains the variance of the prediction compared to the variance of the training data so the score of approximately .53 indicates that a little over half of the variance in the prediction is explained by the variance in the training data. \n\nLet's examine one of the estimators for the age group 0-4 years to see the intercept as well as the coefficients associated with each venue category sorted in descending order. The table below shows the venue categories which increase at the greatest rate in response to a predicted incremental increase in the age group 0-4 years.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 54, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Model Intercept:  0.04315462074507209 \n Model Coefficients:  \n                           Category  Coefficient\n69             Egyptian Restaurant     0.056051\n50                      Comic Shop     0.046842\n28                         Brewery     0.042698\n103                  Historic Site     0.034372\n7                 Asian Restaurant     0.031776\n34                         Butcher     0.031137\n114                 Ice Cream Shop     0.030241\n53      Construction & Landscaping     0.029344\n183                   Soccer Field     0.026890\n71            Ethiopian Restaurant     0.026198\n119            Japanese Restaurant     0.025837\n106                   Hockey Arena     0.021961\n42                  Chocolate Shop     0.021000\n43                          Circus     0.020880\n215                  Women's Store     0.020866\n47                     Coffee Shop     0.020766\n211                Warehouse Store     0.019024\n80                     Flower Shop     0.018490\n61                Department Store     0.018374\n8               Athletics & Sports     0.017780\n144           Other Great Outdoors     0.015718\n179                   Skating Rink     0.015462\n63                           Diner     0.015329\n57                Cuban Restaurant     0.015254\n82               Food & Drink Shop     0.014837\n21                          Bistro     0.014661\n40            Caucasian Restaurant     0.014612\n17                           Beach     0.014165\n115              Indian Restaurant     0.013969\n154                       Pharmacy     0.013200\n..                             ...          ...\n186                            Spa    -0.017116\n188                      Speakeasy    -0.017296\n25                   Bowling Alley    -0.017410\n76            Fast Food Restaurant    -0.018556\n12                      Bagel Shop    -0.019575\n56                        Creperie    -0.020052\n196            Szechuan Restaurant    -0.020811\n15                Baseball Stadium    -0.021873\n187             Spanish Restaurant    -0.021946\n72                     Event Space    -0.022084\n85               French Restaurant    -0.022114\n109                         Hostel    -0.023240\n6              Arts & Crafts Store    -0.023242\n150          Performing Arts Venue    -0.023251\n130       Mediterranean Restaurant    -0.023561\n146           Pakistani Restaurant    -0.023688\n209  Vegetarian / Vegan Restaurant    -0.026006\n5                      Art Gallery    -0.026052\n202                Thai Restaurant    -0.026324\n55                  Cosmetics Shop    -0.027997\n203                        Theater    -0.028977\n157                          Plaza    -0.029140\n176                     Shoe Store    -0.030778\n52                    Concert Hall    -0.030928\n48                     Comedy Club    -0.030944\n172                 Sandwich Place    -0.034319\n131             Mexican Restaurant    -0.035406\n164               Ramen Restaurant    -0.038012\n134                  Movie Theater    -0.039177\n165                    Record Shop    -0.049678\n\n[219 rows x 2 columns]\n"
                }
            ], 
            "source": "age_cat = 0\nsingle_label_coef = pd.DataFrame(list(zip(features.columns.tolist(), best_model.estimators_[age_cat].coef_)), \n               columns =['Category', 'Coefficient']).sort_values('Coefficient', ascending=False) \n\nprint('Model Intercept: ', best_model.estimators_[age_cat].intercept_, '\\n', 'Model Coefficients: ','\\n', single_label_coef)"
        }, 
        {
            "source": "### Clustering \nNext we explore a different approach using clustering algorithms. The algorithm will cluster the neighborhoods based on their demographic data then I will compare the venue categories for the neighborhoods in each cluster in similar cluster based on their frequency and novelty.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 55, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Estimated number of clusters: 14\n"
                }
            ], 
            "source": "from sklearn.cluster import AffinityPropagation\nfrom sklearn import metrics\n# Use labels because that is the most complete data set\n# Using Affinity Prop because dataset is small and to estimate number of clusters\ntoronto_affinity = AffinityPropagation().fit(norm_labels)\n\ncluster_centers_indices = toronto_affinity.cluster_centers_indices_\nalabels = toronto_affinity.labels_\n\nn_clusters = len(cluster_centers_indices)\n\nprint('Estimated number of clusters: %d' % n_clusters)"
        }, 
        {
            "source": "I initially leveraged the Affinity Propagation clustering algorithm to predict the appropriate number of clusters because this is a convenient feature of this particular clustering algorithm and since the dataset it small. I will then use the more traditional KMeans clustering to form the clusters and the following metrics to score (max score = 1) the model. Homogeneity describes how well cluster contains only members of a single label. Completeness measures how well all members of a given label are assigned to the a particular cluster. V-measure represents the harmonic mean between homogeneity and completeness.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 56, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Homogeneity: 0.809\nCompleteness: 0.779\nV-measure: 0.794\n"
                }
            ], 
            "source": "from sklearn.cluster import KMeans\n\n# Advantages to using kmeans is that it scales better for larger datasets\n# 14 clusters provides perfect score on metrics\n# set number of clusters\nkclusters = n_clusters\n\n# cluster neighborhoods by age demographics\ntoronto_clusters = KMeans(n_clusters=kclusters, random_state=0).fit(norm_labels)\nklabels = toronto_clusters.labels_\n\n#Compare clustering models\nprint(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(alabels, klabels))\nprint(\"Completeness: %0.3f\" % metrics.completeness_score(alabels, klabels))\nprint(\"V-measure: %0.3f\" % metrics.v_measure_score(alabels, klabels))"
        }, 
        {
            "execution_count": 57, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Index\n45 to 49 years    5.950862\n40 to 44 years    3.985381\n10 to 14 years    3.978630\n5 to 9 years      3.623529\n50 to 54 years    3.377334\nName: 0, dtype: float64 \n\nIndex\n30 to 34 years    15.346218\n35 to 39 years    13.681714\n25 to 29 years    13.113996\n40 to 44 years     3.929779\n20 to 24 years    -0.619862\nName: 1, dtype: float64 \n\nIndex\n70 to 74 years        6.865712\n65 to 69 years        6.173570\n95 to 99 years        5.106074\n75 to 79 years        4.608758\n100 years and over    4.375913\nName: 2, dtype: float64 \n\nIndex\n40 to 44 years    17.549786\n35 to 39 years    12.338174\n0 to 4 years       8.876693\n45 to 49 years     8.785409\n50 to 54 years     3.395479\nName: 3, dtype: float64 \n\nIndex\n20 to 24 years        7.258659\n25 to 29 years        2.834215\n100 years and over    1.560189\n30 to 34 years        1.156770\n95 to 99 years        1.135773\nName: 4, dtype: float64 \n\nIndex\n40 to 44 years    4.332026\n55 to 59 years    3.308082\n0 to 4 years      3.149284\n35 to 39 years    2.770255\n50 to 54 years    1.957163\nName: 5, dtype: float64 \n\nIndex\n80 to 84 years    8.072958\n75 to 79 years    6.848061\n85 to 89 years    4.620899\n15 to 19 years    3.852886\n10 to 14 years    3.172009\nName: 6, dtype: float64 \n\nIndex\n25 to 29 years    3.967675\n30 to 34 years    3.825786\n35 to 39 years    2.882230\n20 to 24 years    1.126117\n40 to 44 years    0.039004\nName: 7, dtype: float64 \n\nIndex\n75 to 79 years    17.401895\n80 to 84 years    17.097730\n70 to 74 years    16.486322\n85 to 89 years    16.165913\n90 to 94 years    14.464465\nName: 8, dtype: float64 \n\nIndex\n20 to 24 years    12.321712\n25 to 29 years     9.864172\n30 to 34 years     8.017620\n35 to 39 years     3.039716\n95 to 99 years    -2.777526\nName: 9, dtype: float64 \n\nIndex\n0 to 4 years          4.079441\n5 to 9 years          3.375536\n10 to 14 years        1.830718\n100 years and over    1.072805\n40 to 44 years        0.824902\nName: 10, dtype: float64 \n\nIndex\n60 to 64 years    13.869609\n55 to 59 years    13.349524\n50 to 54 years    10.528337\n65 to 69 years     9.626638\n15 to 19 years     8.988595\nName: 11, dtype: float64 \n\nIndex\n15 to 19 years    14.916461\n10 to 14 years    13.166303\n5 to 9 years      12.994862\n0 to 4 years      11.555634\n50 to 54 years     3.393665\nName: 12, dtype: float64 \n\nIndex\n100 years and over    15.301624\n95 to 99 years        15.029382\n90 to 94 years        12.571344\n85 to 89 years         7.946723\n80 to 84 years         4.099083\nName: 13, dtype: float64 \n\n"
                }
            ], 
            "source": "demo_clusters = pd.DataFrame(data = norm_labels[0:,0:], columns=labels.columns)\ndemo_clusters['Labels'] = toronto_clusters.labels_\ndemo_clusters_sum = demo_clusters.groupby(by=['Labels']).sum()\n\n#Show which age groups had greatest occurance above mean in each cluster\nfor label in range(demo_clusters_sum.shape[0]):\n    print(demo_clusters_sum.iloc[label, :].sort_values(ascending = False).head(5), '\\n')"
        }, 
        {
            "execution_count": 58, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "venue_clusters = pd.DataFrame(data = norm_features[0:,0:], columns=features.columns)\nvenue_clusters['Labels'] = toronto_clusters.labels_\nvenue_clusters_sum = venue_clusters.groupby(by=['Labels']).sum()\n\n# Show which venues occured greatest from the mean\n#for label in range(demo_clusters_sum.shape[0]):\n#    print(venue_clusters_sum.iloc[label, :].sort_values(ascending = False).head(5), '\\n')"
        }, 
        {
            "source": "Clustering provides a novel approach to analyzing the relationship between labels and features. We can compare the most interesting labels and features for each cluster by displaying the ones which have the greatest occurance above their normalized mean. Let's examine the top three labels and features for each cluster to see what trends may be apparent.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 60, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Index\n45 to 49 years    5.950862\n40 to 44 years    3.985381\nName: 0, dtype: float64 \n Hotel Bar                9.541599\nComic Shop               4.628448\nIndonesian Restaurant    4.378803\nSoccer Field             4.217249\nName: 0, dtype: float64 \n\nIndex\n30 to 34 years    15.346218\n35 to 39 years    13.681714\nName: 1, dtype: float64 \n Record Shop              13.856406\nSpanish Restaurant       13.639887\nHarbor / Marina          13.344922\nPerforming Arts Venue    13.141043\nName: 1, dtype: float64 \n\nIndex\n70 to 74 years    6.865712\n65 to 69 years    6.173570\nName: 2, dtype: float64 \n Korean Restaurant     6.892195\nHookah Bar            6.565447\nPersian Restaurant    6.565447\nRamen Restaurant      6.313863\nName: 2, dtype: float64 \n\nIndex\n40 to 44 years    17.549786\n35 to 39 years    12.338174\nName: 3, dtype: float64 \n Circus                 16.426303\nComic Shop             13.529311\nAmerican Restaurant    13.528950\nIce Cream Shop         12.557368\nName: 3, dtype: float64 \n\nIndex\n20 to 24 years    7.258659\n25 to 29 years    2.834215\nName: 4, dtype: float64 \n Sandwich Place        5.883171\nSpanish Restaurant    5.865151\nComedy Club           5.559594\nShoe Store            4.840307\nName: 4, dtype: float64 \n\nIndex\n40 to 44 years    4.332026\n55 to 59 years    3.308082\nName: 5, dtype: float64 \n Food Court                 10.506703\nSeafood Restaurant          9.847475\nFurniture / Home Store      8.510645\nComfort Food Restaurant     7.923548\nName: 5, dtype: float64 \n\nIndex\n80 to 84 years    8.072958\n75 to 79 years    6.848061\nName: 6, dtype: float64 \n Hockey Arena     9.711358\nBoutique         9.346852\nBike Shop        8.684112\nJewelry Store    8.684112\nName: 6, dtype: float64 \n\nIndex\n25 to 29 years    3.967675\n30 to 34 years    3.825786\nName: 7, dtype: float64 \n Harbor / Marina          4.795832\nMusic Venue              4.266146\nSoccer Stadium           3.872983\nPerforming Arts Venue    3.565710\nName: 7, dtype: float64 \n\nIndex\n75 to 79 years    17.401895\n80 to 84 years    17.097730\nName: 8, dtype: float64 \n Tattoo Parlor         15.423758\nHotpot Restaurant     11.155920\nNoodle House          10.479913\nChinese Restaurant    10.393200\nName: 8, dtype: float64 \n\nIndex\n20 to 24 years    12.321712\n25 to 29 years     9.864172\nName: 9, dtype: float64 \n Comedy Club            11.119189\nShoe Store              9.680614\nAquarium                9.648363\nMonument / Landmark     9.005745\nName: 9, dtype: float64 \n\nIndex\n0 to 4 years    4.079441\n5 to 9 years    3.375536\nName: 10, dtype: float64 \n Comic Shop             3.441667\nHistoric Site          3.203224\nEgyptian Restaurant    3.109126\nCoffee Shop            2.498622\nName: 10, dtype: float64 \n\nIndex\n60 to 64 years    13.869609\n55 to 59 years    13.349524\nName: 11, dtype: float64 \n Beach                   12.260943\nBreakfast Spot          11.580715\nSports Bar               9.607689\nHungarian Restaurant     9.339476\nName: 11, dtype: float64 \n\nIndex\n15 to 19 years    14.916461\n10 to 14 years    13.166303\nName: 12, dtype: float64 \n Warehouse Store      15.627144\nPoutine Place        12.651746\nAfghan Restaurant    12.651746\nConvenience Store    12.651746\nName: 12, dtype: float64 \n\nIndex\n100 years and over    15.301624\n95 to 99 years        15.029382\nName: 13, dtype: float64 \n Music School             8.926012\nIndonesian Restaurant    8.132062\nFlower Shop              6.662501\nTea Room                 6.595253\nName: 13, dtype: float64 \n\n"
                }
            ], 
            "source": "for label in range(demo_clusters_sum.shape[0]):\n    print((demo_clusters_sum.iloc[label, :]).sort_values(ascending = False).head(2),'\\n', \n          venue_clusters_sum.iloc[label, venue_clusters_sum.columns != 'Labels'].sort_values(ascending = False).head(4),'\\n')"
        }, 
        {
            "source": "### Results\n\nDue to the small sample size of only 96 neighborhoods and the large number of demographic and venue category labels (21 and 220 respectively), it is difficult to train and test a machine learning model on such a dataset. It is also important to note that there are less multioutput regression models available to experiment with the scope of this study than say single output regression or a classification problem. Despite the deficits in the supply of data discussed previously, several of the models performed surprisingly well. \n\nThe Bayesian Ridge linear regressor in particular was able to explain almost 50% of the local demographic data based on the local venue category data. Some of the most apparent relationships occured with the gym and athletic venues being more popular among the ages 20 - 34 and the BBQ Joint which reigns supreme between the ages 45 - 74 which is then gradually replaced by asian and mediterrainian restaurants. \n\nThe clustering model seemed to group people who are close in age together the most which also revealed some relationships among particular venue categories. Interestingly, similar venue categories did not seem appear for the same age groups but which were in different clusters.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Discussion\n\nThis experimental study provides lots of space for further discussion and exploration. It would of course be useful to include more cities and larger venue category datasets in a future study but even given the results from this small study some important observations can be made. \n\nThe relationship between the demographic and venue data can be more nuanced. For example, when examining the Bayesian Ridge regression model the estimator coefficients for the age group 0-4 show Egyptian restaurant, comic shop and brewery listed as the three most positively impacted venue categories which may seem counterintuitive however it is important to remember that people in the youngest age groups likely live with their parents who would be the ones using these venues. The clustering model provided a novel perspective of the relationship by associating some new venue categories with different age groups such as hotel bars being associated with people in their fourties or Comedy Clubs being popular with people in their twenties. It also revealed similar trends observed by the regression model such as fitness and outdoor related venues more popular among younger adults as well as restaurants of various Asian cuisines tending to be more popular among older adults. The clustering model also supported the relationship of the comic shop and Egyptian restaurant (but not the brewery) to the youngest age groups shown in the linear regressor coefficients.\n\nOne distinct type of venue category that relates to many different age demographics is restaurants of various cuisines. Given how ethnically diverse the city of Toronto is, examining its historic inflows of different ethnic populations immigrating at different time periods could provide more insight into the relationship between specific types of restaurants and local age demographics. This type of relationship may not be consistent in other cities or cities in other countries. Consequently, even though different venue categories of restaurants are very prevalent, they may not generalize well and perhaps should be merged into broader categories or simply as restaurants in order to pursue a model that could be applied more generally. This same rationale could be used to combine other venue categories into broader venue categories thus significantly shrinking the total number of feature categories especially if the neighborhood sample size is small.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Conclusion", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The purpose of this case study was primarily exploratory and experimental with the goal to understand novel approaches to improve methodologies for building demographic maps. Several different machine learning techniques were utilized to explore the relationship between neighborhood age demographic data and venue category data in the city of Toronto. For this type of multioutput regression problem it seems that a linear regression model such as Bayesian Ridge may produce estimators with the highest prediction efficacy. The clustering approach provides novel insights as well as supporting findings from the regression model making the two approaches complementary for this type of problem.\n\nWhile the regression and clustering approaches can be mutually beneficial for mondeling local demographics based on local venues, there are still unique combinations of venues that arise in response to cultural, ethnic and other unique factors. In order to achieve a more  generalized model for predicting age demographics, forming broader feature categories in order to create more generalized neighborhood profiles could contribute to the methodology.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "*For questions of comments please follow up at adahlstromcg@gmail.com*", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}